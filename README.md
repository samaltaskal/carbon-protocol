# Carbon Protocol SDK

High-performance deterministic semantic compression library for LLM prompts using Aho-Corasick multi-pattern matching.

![License](https://img.shields.io/badge/license-MIT-green)
![Status](https://img.shields.io/badge/status-Patent%20Pending-blue)
![Paper](https://img.shields.io/badge/ICT4S-Submitted-orange)
[![DOI](https://img.shields.io/badge/DOI-10.5281%2Fzenodo.18284932-blue)](https://doi.org/10.5281/zenodo.18284932)
![Python](https://img.shields.io/badge/python-3.10+-blue)
![Tests](https://img.shields.io/badge/tests-61%20passing-brightgreen)

> **"Shift Left" for Green AI:** Client-side semantic compression with <10ms latency and 25%+ token reduction.

**Paper Submission:** [Zero-Overhead Prompt Compression: A Deterministic Protocol for Energy-Efficient Generative AI](https://doi.org/10.5281/zenodo.18284932) (Submitted to ICT4S 2026)

## ðŸ“„ Overview

The Carbon Protocol SDK implements deterministic semantic compression using the Aho-Corasick algorithm to achieve O(n) multi-pattern matching. By compressing prompts before they reach LLM APIs, it reduces token usage, carbon emissions, and costs.

**Key Innovation**: Single-pass multi-pattern matching instead of naive O(mÃ—n) sequential replacement.

## ðŸš€ Key Features

- **O(n) Complexity**: Aho-Corasick algorithm ensures linear-time compression
- **<10ms Latency**: Average compression time of 0.85ms for typical prompts
- **25%+ Token Reduction**: Validated across 15 representative prompt categories
- **Modular Domains**: Load only the patterns you need (core, k8s, python, sql)
- **Longest-Match-First**: Deterministic output with proper overlap handling
- **Type-Safe**: Full Python 3.10+ type hints

## ðŸ“¦ Installation

### Via pip (Recommended)
```bash
pip install carbon-protocol
```

### From Source
```bash
# Clone repository
git clone https://github.com/samaltaskal/carbon-protocol.git
cd carbon-protocol

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install in development mode
pip install -e ".[dev]"
```

## âš¡ Quick Start

```python
from carbon_protocol import Registry, Compiler

# Initialize and load domain patterns
registry = Registry()
registry.load_domain('core')
registry.build_automaton()

# Create compiler and compress
compiler = Compiler(registry)
result = compiler.compress("Could you please write a python script to scrape data?")

print(f"Original:   {result.original}")
print(f"Compressed: {result.compressed}")
print(f"Tokens Saved: {result.matches_found}")
# Output: "Compressed: @LANG:PY to @ACT:SCRAPE?"
```

## ðŸ“Š Validated Results

From SDK validation suite (VAL-20260117):

| Metric | Value |
|--------|-------|
| **Average Token Reduction** | 25.8% |
| **Compression Ratio** | 0.74 |
| **Carbon Saved (1M requests/year)** | 0.91 kg CO2 |
| **Cost Saved (1M requests/year)** | $64 USD |
| **Test Coverage** | 52 tests, 100% pass rate |

## ðŸ§ª Testing & Validation

### Run All Tests
```bash
# Standard test suite (52 tests)
pytest tests/ -v

# With IEEE 829 report generation
pytest --ieee-report --ieee-json

# Or use test runner
python run_tests.py --ieee
```

### SDK Validation Tests
```bash
# Run validation/impact assessment
python run_tests.py --validation

# Direct run with detailed output
pytest tests/test_validation.py -v -s
```

**Validation tests capture**:
- Token usage: With SDK vs Without SDK
- Environmental impact: Carbon emissions, energy, water
- Economic impact: API cost savings
- Annual projections: Scaled to 1M requests
- IEEE-compliant reports: Suitable for submission to authorities

See [Validation Testing Guide](docs/guides/validation-testing.md) for details.

## ðŸ“ Project Structure

```
carbon-protocol/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ registry.py         # Pattern loading & Aho-Corasick automaton
â”‚   â”œâ”€â”€ compiler.py         # O(n) compression engine
â”‚   â”œâ”€â”€ metrics.py          # Impact metrics calculator
â”‚   â””â”€â”€ data/               # Domain YAML files
â”œâ”€â”€ tests/                  # Test suite
â”‚   â”œâ”€â”€ test_registry.py    # Registry unit tests (16 tests)
â”‚   â”œâ”€â”€ test_compiler.py    # Compiler unit tests (19 tests)
â”‚   â”œâ”€â”€ test_integration.py # Integration tests (17 tests)
â”‚   â”œâ”€â”€ test_validation.py  # SDK validation tests (5 tests)
â”‚   â””â”€â”€ results/            # Test results by date
â”‚       â””â”€â”€ YYYY-MM-DD/     # Date-based folders
â”œâ”€â”€ docs/                   # Documentation
â”‚   â”œâ”€â”€ api/                # API reference
â”‚   â”œâ”€â”€ guides/             # User guides
â”‚   â””â”€â”€ architecture/       # System design
â””â”€â”€ run_tests.py            # Test runner script
```

## ðŸ“– Documentation

- [Getting Started](docs/guides/getting-started.md) - Quick start guide
- [API Reference](docs/api/README.md) - Complete API documentation  
- [Architecture Overview](docs/architecture/overview.md) - System design
- [Validation Testing](docs/guides/validation-testing.md) - Impact assessment

## ðŸ”¬ Architecture

### Aho-Corasick Algorithm

**Why not naive string replacement?**

```python
# âŒ Naive O(mÃ—n) - Too slow
for pattern in patterns:      # m patterns
    text = text.replace(...)  # n characters
# Result: 1000 patterns Ã— 10KB text = 10M operations

# âœ… Aho-Corasick O(n) - Fast  
automaton.find_all(text)      # Single pass
# Result: 10KB text = 10K operations (1000Ã— faster!)
```

### Performance Characteristics

| Operation | Complexity | Time (typical) |
|-----------|------------|----------------|
| Domain loading | O(p) | 10-15ms |
| Automaton build | O(m) | 10-15ms |
| Single compression | O(n + z) | 0.85ms |
| Batch (500 prompts) | O(n + z) | 1.5ms |

## ðŸŒ Environmental Impact

Based on validation testing with 15 representative prompts:

**Per Sample Set (15 prompts)**:
- Energy Saved: 0.000029 kWh
- Carbon Saved: 0.0137 grams CO2
- Water Saved: 0.000052 liters

**Projected Annual (1M requests)**:
- Tokens Saved: 6.4 million
- Carbon Saved: 0.91 kg CO2 (â‰ˆ2.3 tree-days)
- Cost Saved: $64 USD

*Calculations based on peer-reviewed research (Patterson et al., 2021) and IEA carbon intensity data.*

## ðŸ’° Cost Savings

Assuming $0.01 per 1K input tokens (conservative estimate):

| Request Volume | Token Reduction | Annual Savings |
|----------------|-----------------|----------------|
| 100K requests  | 640K tokens     | $6.40 |
| 1M requests    | 6.4M tokens     | $64.00 |
| 10M requests   | 64M tokens      | $640.00 |
| 100M requests  | 640M tokens     | $6,400.00 |

*Actual savings scale with API pricing and request patterns.*

## ðŸ§‘â€ðŸ’» Contributing

Contributions welcome! Areas of interest:
- Additional domain files (k8s, sql, devops, etc.)
- Performance optimizations
- Additional test scenarios
- Documentation improvements

## ðŸ“„ License

MIT License - See [LICENSE](LICENSE) file

## ðŸ“š References

1. Patterson, D., et al. (2021). "Carbon Emissions and Large Neural Network Training." arXiv:2104.10350
2. Aho, A.V., & Corasick, M.J. (1975). "Efficient string matching: An aid to bibliographic search." CACM 18(6)
3. IEA (2023). "Global Energy & CO2 Status Report"

## ðŸ™ Acknowledgments

This SDK implements the Carbon Protocol specification for deterministic semantic compression, targeting ICT4S 2026 submission.

âš–ï¸ License & IP
Copyright (c) 2026 Taskal Samal. This reference implementation is released under the MIT License to foster academic collaboration and sustainable AI development. Patent Pending (USPTO Application No. 63/961,716)
