#!/usr/bin/env python3
"""
Carbon Protocol Dictionary Builder

Automatically generates YAML dictionary files from various sources:
1. Python/SQL reserved keywords
2. VS Code snippets from GitHub
3. Cloud CLI commands (AWS, Azure, GCP)

Usage:
    python build_dictionary.py --all                    # Build all dictionaries
    python build_dictionary.py --python                 # Python keywords only
    python build_dictionary.py --sql                    # SQL keywords only
    python build_dictionary.py --kubernetes             # Kubernetes snippets
    python build_dictionary.py --aws                    # AWS CLI commands
    python build_dictionary.py --azure                  # Azure CLI commands
    python build_dictionary.py --gcp                    # GCP CLI commands
    python build_dictionary.py --vscode-url <url>       # Custom VS Code snippets URL

Output:
    src/data/lang_python.yaml
    src/data/lang_sql.yaml
    src/data/cloud_aws.yaml
    src/data/cloud_azure.yaml
    src/data/cloud_gcp.yaml
    src/data/tools_kubernetes.yaml
"""

import argparse
import csv
import json
import keyword
import io
import re
import subprocess
import sys
import yaml
from datetime import datetime
from pathlib import Path
from typing import Any
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError


# =============================================================================
# Configuration
# =============================================================================

OUTPUT_DIR = Path(__file__).parent.parent / "src" / "data"

# VS Code Snippet URLs
VSCODE_SNIPPET_URLS = {
    "kubernetes_helm": "https://raw.githubusercontent.com/vscode-kubernetes-tools/vscode-kubernetes-tools/main/snippets/helm.json",
    "docker": "https://raw.githubusercontent.com/microsoft/vscode-docker/main/resources/snippets/dockerfile.json",
}

# User agent for web requests
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Carbon-Protocol-Dictionary-Builder/1.0"


# =============================================================================
# YAML Generation Utilities
# =============================================================================

def generate_yaml_header(source: str, domain: str) -> str:
    """Generate YAML file header with metadata."""
    return f'''# Carbon Protocol Dictionary - {domain}
# Generated by: build_dictionary.py
# Source: {source}
# Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
# 
# Format: "raw phrase": "COMPRESSED_TOKEN"
# Tokens follow the pattern: @CATEGORY:VALUE or @CATEGORY:SUBCATEGORY:VALUE

'''


def to_token(prefix: str, value: str) -> str:
    """Convert a value to a compressed token format."""
    # Clean and normalize the value
    clean = re.sub(r'[^a-zA-Z0-9_\-]', '_', value.upper())
    clean = re.sub(r'_+', '_', clean).strip('_')
    return f"@{prefix}:{clean}"


def save_yaml(filepath: Path, patterns: dict[str, str], source: str, domain: str):
    """Save patterns to a YAML file."""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(generate_yaml_header(source, domain))
        f.write("patterns:\n")
        
        # Sort patterns by key for consistency
        for key in sorted(patterns.keys()):
            value = patterns[key]
            # Escape quotes in keys
            escaped_key = key.replace('"', '\\"')
            f.write(f'  "{escaped_key}": "{value}"\n')
    
    print(f"  [OK] Saved {len(patterns)} patterns to {filepath}")


# =============================================================================
# SOURCE 1: Reserved Keywords (Python/SQL)
# =============================================================================

def build_python_keywords() -> dict[str, str]:
    """Extract Python reserved keywords and built-in functions."""
    patterns = {}
    
    # Python keywords
    for kw in keyword.kwlist:
        patterns[kw] = to_token("PY", kw)
    
    # Python soft keywords (Python 3.10+)
    if hasattr(keyword, 'softkwlist'):
        for kw in keyword.softkwlist:
            patterns[kw] = to_token("PY", kw)
    
    # Common Python built-in functions
    builtins = [
        "print", "len", "range", "str", "int", "float", "list", "dict", "set",
        "tuple", "bool", "type", "input", "open", "file", "read", "write",
        "append", "extend", "pop", "remove", "insert", "sort", "sorted",
        "reverse", "reversed", "enumerate", "zip", "map", "filter", "reduce",
        "sum", "min", "max", "abs", "round", "pow", "divmod", "hex", "oct",
        "bin", "ord", "chr", "format", "repr", "hash", "id", "dir", "vars",
        "locals", "globals", "hasattr", "getattr", "setattr", "delattr",
        "isinstance", "issubclass", "callable", "iter", "next", "slice",
        "staticmethod", "classmethod", "property", "super", "object",
        "compile", "exec", "eval", "help", "exit", "quit",
    ]
    
    for builtin in builtins:
        if builtin not in patterns:
            patterns[builtin] = to_token("PY:FUNC", builtin)
    
    # Python common phrases
    phrases = {
        "python script": "@LANG:PY",
        "python code": "@LANG:PY",
        "python function": "@PY:FUNC",
        "python class": "@PY:CLASS",
        "python module": "@PY:MODULE",
        "python package": "@PY:PKG",
        "python library": "@PY:LIB",
        "import statement": "@PY:IMPORT",
        "pip install": "@PY:PIP_INSTALL",
        "virtual environment": "@PY:VENV",
        "virtualenv": "@PY:VENV",
        "requirements.txt": "@PY:REQUIREMENTS",
        "setup.py": "@PY:SETUP",
        "pyproject.toml": "@PY:PYPROJECT",
        "__init__.py": "@PY:INIT",
        "__main__.py": "@PY:MAIN",
        "if __name__": "@PY:MAIN_GUARD",
        "try except": "@PY:TRY_EXCEPT",
        "try finally": "@PY:TRY_FINALLY",
        "with statement": "@PY:WITH",
        "context manager": "@PY:CTX_MGR",
        "decorator": "@PY:DECORATOR",
        "generator": "@PY:GENERATOR",
        "list comprehension": "@PY:LIST_COMP",
        "dict comprehension": "@PY:DICT_COMP",
        "lambda function": "@PY:LAMBDA",
        "async function": "@PY:ASYNC_FUNC",
        "await": "@PY:AWAIT",
        "asyncio": "@PY:ASYNCIO",
        "type hint": "@PY:TYPE_HINT",
        "dataclass": "@PY:DATACLASS",
        "namedtuple": "@PY:NAMEDTUPLE",
        "unittest": "@PY:UNITTEST",
        "pytest": "@PY:PYTEST",
    }
    patterns.update(phrases)
    
    return patterns


def build_sql_keywords() -> dict[str, str]:
    """Generate SQL reserved keywords and common commands."""
    patterns = {}
    
    # SQL Keywords
    sql_keywords = [
        # DML (Data Manipulation Language)
        "SELECT", "INSERT", "UPDATE", "DELETE", "MERGE", "UPSERT",
        "FROM", "WHERE", "AND", "OR", "NOT", "IN", "BETWEEN", "LIKE",
        "IS NULL", "IS NOT NULL", "EXISTS", "ANY", "ALL",
        "ORDER BY", "GROUP BY", "HAVING", "LIMIT", "OFFSET", "FETCH",
        "DISTINCT", "TOP", "PERCENT", "WITH TIES",
        
        # Joins
        "JOIN", "INNER JOIN", "LEFT JOIN", "RIGHT JOIN", "FULL JOIN",
        "LEFT OUTER JOIN", "RIGHT OUTER JOIN", "FULL OUTER JOIN",
        "CROSS JOIN", "NATURAL JOIN", "SELF JOIN", "ON", "USING",
        
        # Set Operations
        "UNION", "UNION ALL", "INTERSECT", "EXCEPT", "MINUS",
        
        # Aggregates
        "COUNT", "SUM", "AVG", "MIN", "MAX", "FIRST", "LAST",
        "GROUP_CONCAT", "STRING_AGG", "ARRAY_AGG",
        
        # DDL (Data Definition Language)
        "CREATE", "ALTER", "DROP", "TRUNCATE", "RENAME",
        "CREATE TABLE", "CREATE INDEX", "CREATE VIEW", "CREATE PROCEDURE",
        "CREATE FUNCTION", "CREATE TRIGGER", "CREATE DATABASE", "CREATE SCHEMA",
        "ALTER TABLE", "ALTER INDEX", "ALTER VIEW", "ALTER PROCEDURE",
        "DROP TABLE", "DROP INDEX", "DROP VIEW", "DROP PROCEDURE",
        "DROP DATABASE", "DROP SCHEMA",
        
        # Constraints
        "PRIMARY KEY", "FOREIGN KEY", "UNIQUE", "CHECK", "DEFAULT",
        "NOT NULL", "AUTO_INCREMENT", "IDENTITY", "SERIAL",
        "REFERENCES", "CASCADE", "SET NULL", "SET DEFAULT", "RESTRICT",
        
        # DCL (Data Control Language)
        "GRANT", "REVOKE", "DENY",
        
        # TCL (Transaction Control Language)
        "COMMIT", "ROLLBACK", "SAVEPOINT", "BEGIN", "START TRANSACTION",
        "END TRANSACTION", "SET TRANSACTION",
        
        # Data Types
        "INT", "INTEGER", "BIGINT", "SMALLINT", "TINYINT",
        "DECIMAL", "NUMERIC", "FLOAT", "REAL", "DOUBLE",
        "CHAR", "VARCHAR", "TEXT", "NCHAR", "NVARCHAR", "NTEXT",
        "DATE", "TIME", "DATETIME", "TIMESTAMP", "YEAR",
        "BOOLEAN", "BOOL", "BIT", "BINARY", "VARBINARY", "BLOB",
        "JSON", "XML", "UUID", "GUID",
        
        # Functions
        "COALESCE", "NULLIF", "CASE WHEN", "CASE", "WHEN", "THEN", "ELSE", "END",
        "CAST", "CONVERT", "TRY_CAST", "TRY_CONVERT",
        "SUBSTRING", "LEFT", "RIGHT", "TRIM", "LTRIM", "RTRIM",
        "UPPER", "LOWER", "LENGTH", "LEN", "CONCAT", "REPLACE",
        "ROUND", "FLOOR", "CEILING", "ABS", "POWER", "SQRT",
        "GETDATE", "NOW", "CURRENT_DATE", "CURRENT_TIME", "CURRENT_TIMESTAMP",
        "DATEADD", "DATEDIFF", "DATEPART", "YEAR", "MONTH", "DAY",
        
        # Window Functions
        "OVER", "PARTITION BY", "ROW_NUMBER", "RANK", "DENSE_RANK",
        "NTILE", "LAG", "LEAD", "FIRST_VALUE", "LAST_VALUE",
        
        # Other
        "AS", "ALIAS", "INTO", "VALUES", "SET", "EXEC", "EXECUTE",
        "DECLARE", "CURSOR", "OPEN", "CLOSE", "FETCH NEXT",
        "INDEX", "CLUSTERED", "NONCLUSTERED", "UNIQUE INDEX",
        "VIEW", "MATERIALIZED VIEW", "TEMPORARY", "TEMP",
        "STORED PROCEDURE", "FUNCTION", "TRIGGER",
        "CTE", "WITH", "RECURSIVE",
    ]
    
    for kw in sql_keywords:
        patterns[kw.lower()] = to_token("SQL", kw.replace(" ", "_"))
    
    # SQL common phrases
    phrases = {
        "sql query": "@LANG:SQL",
        "sql statement": "@LANG:SQL",
        "database query": "@SQL:QUERY",
        "run query": "@SQL:EXEC",
        "execute query": "@SQL:EXEC",
        "select all": "@SQL:SELECT_ALL",
        "select from": "@SQL:SELECT_FROM",
        "insert into": "@SQL:INSERT_INTO",
        "update table": "@SQL:UPDATE",
        "delete from": "@SQL:DELETE_FROM",
        "create table": "@SQL:CREATE_TABLE",
        "drop table": "@SQL:DROP_TABLE",
        "alter table": "@SQL:ALTER_TABLE",
        "add column": "@SQL:ADD_COL",
        "drop column": "@SQL:DROP_COL",
        "rename column": "@SQL:RENAME_COL",
        "primary key": "@SQL:PK",
        "foreign key": "@SQL:FK",
        "join tables": "@SQL:JOIN",
        "inner join": "@SQL:INNER_JOIN",
        "left join": "@SQL:LEFT_JOIN",
        "right join": "@SQL:RIGHT_JOIN",
        "group by": "@SQL:GROUP_BY",
        "order by": "@SQL:ORDER_BY",
        "where clause": "@SQL:WHERE",
        "having clause": "@SQL:HAVING",
        "subquery": "@SQL:SUBQUERY",
        "stored procedure": "@SQL:SPROC",
        "user defined function": "@SQL:UDF",
        "database schema": "@SQL:SCHEMA",
        "database index": "@SQL:INDEX",
        "database view": "@SQL:VIEW",
        "database trigger": "@SQL:TRIGGER",
        "transaction": "@SQL:TXN",
        "commit transaction": "@SQL:COMMIT",
        "rollback transaction": "@SQL:ROLLBACK",
    }
    patterns.update(phrases)
    
    return patterns


# =============================================================================
# SOURCE 2: VS Code Snippets (Web Scraping)
# =============================================================================

def fetch_url(url: str) -> str | None:
    """Fetch content from a URL with proper headers."""
    try:
        request = Request(url, headers={"User-Agent": USER_AGENT})
        with urlopen(request, timeout=30) as response:
            return response.read().decode('utf-8')
    except HTTPError as e:
        print(f"  [ERROR] HTTP Error {e.code}: {url}")
        return None
    except URLError as e:
        print(f"  [ERROR] URL Error: {e.reason}")
        return None
    except Exception as e:
        print(f"  [ERROR] Failed to fetch URL: {e}")
        return None


def parse_vscode_snippets(json_content: str, prefix: str) -> dict[str, str]:
    """Parse VS Code snippets JSON and convert to Carbon Protocol format."""
    patterns = {}
    
    try:
        snippets = json.loads(json_content)
    except json.JSONDecodeError as e:
        print(f"  [ERROR] Failed to parse JSON: {e}")
        return patterns
    
    for name, snippet in snippets.items():
        # Get the prefix (trigger text)
        snippet_prefix = snippet.get("prefix", "")
        if isinstance(snippet_prefix, list):
            snippet_prefix = snippet_prefix[0] if snippet_prefix else ""
        
        if not snippet_prefix:
            continue
        
        # Generate token from snippet name or prefix
        token_value = name.replace(" ", "_").replace("-", "_")
        token = to_token(prefix, token_value)
        
        # Add the prefix as the pattern
        patterns[snippet_prefix.lower()] = token
        
        # Also add the snippet name if different
        name_lower = name.lower().replace("_", " ").replace("-", " ")
        if name_lower != snippet_prefix.lower():
            patterns[name_lower] = token
    
    return patterns


def build_vscode_snippets(url: str, prefix: str, name: str) -> dict[str, str]:
    """Fetch and parse VS Code snippets from a GitHub URL."""
    print(f"  Fetching {name} snippets from GitHub...")
    
    content = fetch_url(url)
    if content is None:
        return {}
    
    return parse_vscode_snippets(content, prefix)


def build_kubernetes_dictionary() -> dict[str, str]:
    """Build Kubernetes dictionary from VS Code snippets and common commands."""
    patterns = {}
    
    # Base URL for snippets source
    base_url = "https://raw.githubusercontent.com/vscode-kubernetes-tools/vscode-kubernetes-tools/main/snippets"

    # 1. Fetch Helm snippets (JSON format)
    helm_url = f"{base_url}/helm.json"
    snippets = build_vscode_snippets(helm_url, "K8S:HELM", "Kubernetes Helm")
    patterns.update(snippets)
    
    # 2. Fetch Kubernetes YAML snippets
    yaml_files = [
        "configmap.yaml", "cronjob.yaml", "deployment.yaml", "hpa.yaml", 
        "ingress.yaml", "job.yaml", "persistentvolume.yaml", 
        "persistentvolumeclaim.yaml", "pod.yaml", "replicaset.yaml", 
        "replicationcontroller.yaml", "secret.yaml", "service.yaml", 
        "statefulset.yaml"
    ]
    
    print("  Fetching Kubernetes YAML snippets...")
    for fname in yaml_files:
        url = f"{base_url}/{fname}"
        content = fetch_url(url)
        if content:
            try:
                # Use yaml.safe_load to parse the content
                data = yaml.safe_load(content)
                if isinstance(data, dict):
                    name = data.get("name")
                    if name:
                        # Clean name and create token
                        clean_name = name.lower().replace("-", " ")
                        token = to_token("K8S", name.replace(" ", "_"))
                        patterns[clean_name] = token
                        
                        # Add filename alias if different
                        fname_base = fname.replace(".yaml", "").replace("-", " ")
                        if fname_base != clean_name:
                             patterns[fname_base] = token
            except Exception as e:
                print(f"    [WARN] Failed to parse {fname}: {e}")
    
    # Add common Kubernetes commands and resources
    k8s_resources = [
        "pod", "pods", "deployment", "deployments", "service", "services",
        "configmap", "configmaps", "secret", "secrets", "namespace", "namespaces",
        "node", "nodes", "persistentvolume", "persistentvolumeclaim", "pv", "pvc",
        "replicaset", "replicasets", "daemonset", "daemonsets", "statefulset",
        "job", "jobs", "cronjob", "cronjobs", "ingress", "networkpolicy",
        "serviceaccount", "role", "rolebinding", "clusterrole", "clusterrolebinding",
        "horizontalpodautoscaler", "hpa", "verticalpodautoscaler", "vpa",
        "poddisruptionbudget", "pdb", "resourcequota", "limitrange",
        "storageclass", "volumesnapshot", "customresourcedefinition", "crd",
    ]
    
    for resource in k8s_resources:
        patterns[resource] = to_token("K8S", resource)
    
    # kubectl commands
    kubectl_commands = {
        "kubectl": "@K8S:KUBECTL",
        "kubectl get": "@K8S:GET",
        "kubectl describe": "@K8S:DESCRIBE",
        "kubectl create": "@K8S:CREATE",
        "kubectl apply": "@K8S:APPLY",
        "kubectl delete": "@K8S:DELETE",
        "kubectl edit": "@K8S:EDIT",
        "kubectl logs": "@K8S:LOGS",
        "kubectl exec": "@K8S:EXEC",
        "kubectl port-forward": "@K8S:PORT_FWD",
        "kubectl scale": "@K8S:SCALE",
        "kubectl rollout": "@K8S:ROLLOUT",
        "kubectl rollout restart": "@K8S:ROLLOUT_RESTART",
        "kubectl rollout status": "@K8S:ROLLOUT_STATUS",
        "kubectl rollout undo": "@K8S:ROLLOUT_UNDO",
        "kubectl config": "@K8S:CONFIG",
        "kubectl config use-context": "@K8S:USE_CTX",
        "kubectl config get-contexts": "@K8S:GET_CTX",
        "kubectl cluster-info": "@K8S:CLUSTER_INFO",
        "kubectl top": "@K8S:TOP",
        "kubectl top pods": "@K8S:TOP_PODS",
        "kubectl top nodes": "@K8S:TOP_NODES",
        "kubectl label": "@K8S:LABEL",
        "kubectl annotate": "@K8S:ANNOTATE",
        "kubectl taint": "@K8S:TAINT",
        "kubectl cordon": "@K8S:CORDON",
        "kubectl uncordon": "@K8S:UNCORDON",
        "kubectl drain": "@K8S:DRAIN",
    }
    patterns.update(kubectl_commands)
    
    # Kubernetes phrases
    phrases = {
        "kubernetes cluster": "@K8S:CLUSTER",
        "kubernetes namespace": "@K8S:NS",
        "kubernetes deployment": "@K8S:DEPLOY",
        "kubernetes service": "@K8S:SVC",
        "kubernetes pod": "@K8S:POD",
        "kubernetes configmap": "@K8S:CM",
        "kubernetes secret": "@K8S:SECRET",
        "kubernetes ingress": "@K8S:INGRESS",
        "kubernetes manifest": "@K8S:MANIFEST",
        "kubernetes yaml": "@K8S:YAML",
        "helm chart": "@K8S:HELM",
        "helm install": "@K8S:HELM_INSTALL",
        "helm upgrade": "@K8S:HELM_UPGRADE",
        "helm uninstall": "@K8S:HELM_UNINSTALL",
        "container image": "@K8S:IMAGE",
        "container registry": "@K8S:REGISTRY",
        "docker image": "@K8S:DOCKER_IMG",
        "container port": "@K8S:PORT",
        "environment variable": "@K8S:ENV_VAR",
        "resource limits": "@K8S:LIMITS",
        "resource requests": "@K8S:REQUESTS",
        "liveness probe": "@K8S:LIVENESS",
        "readiness probe": "@K8S:READINESS",
        "startup probe": "@K8S:STARTUP",
        "init container": "@K8S:INIT_CTR",
        "sidecar container": "@K8S:SIDECAR",
        "persistent volume": "@K8S:PV",
        "persistent volume claim": "@K8S:PVC",
        "storage class": "@K8S:SC",
        "load balancer": "@K8S:LB",
        "cluster ip": "@K8S:CLUSTER_IP",
        "node port": "@K8S:NODE_PORT",
        "network policy": "@K8S:NETPOL",
        "service mesh": "@K8S:MESH",
        "istio": "@K8S:ISTIO",
        "linkerd": "@K8S:LINKERD",
    }
    patterns.update(phrases)
    
    return patterns


# =============================================================================
# SOURCE 3: Cloud CLI Commands (AWS/Azure/GCP)
# =============================================================================

def build_aws_dictionary() -> dict[str, str]:
    """Build AWS CLI dictionary from common commands and services."""
    patterns = {}
    
    # AWS Services
    aws_services = [
        # Compute
        ("ec2", "Elastic Compute Cloud"),
        ("lambda", "Lambda"),
        ("ecs", "Elastic Container Service"),
        ("eks", "Elastic Kubernetes Service"),
        ("fargate", "Fargate"),
        ("batch", "Batch"),
        ("lightsail", "Lightsail"),
        ("elastic-beanstalk", "Elastic Beanstalk"),
        
        # Storage
        ("s3", "Simple Storage Service"),
        ("ebs", "Elastic Block Store"),
        ("efs", "Elastic File System"),
        ("fsx", "FSx"),
        ("glacier", "Glacier"),
        ("storage-gateway", "Storage Gateway"),
        
        # Database
        ("rds", "Relational Database Service"),
        ("dynamodb", "DynamoDB"),
        ("elasticache", "ElastiCache"),
        ("redshift", "Redshift"),
        ("neptune", "Neptune"),
        ("documentdb", "DocumentDB"),
        ("aurora", "Aurora"),
        
        # Networking
        ("vpc", "Virtual Private Cloud"),
        ("cloudfront", "CloudFront"),
        ("route53", "Route 53"),
        ("elb", "Elastic Load Balancing"),
        ("alb", "Application Load Balancer"),
        ("nlb", "Network Load Balancer"),
        ("api-gateway", "API Gateway"),
        ("direct-connect", "Direct Connect"),
        
        # Security
        ("iam", "Identity and Access Management"),
        ("cognito", "Cognito"),
        ("kms", "Key Management Service"),
        ("secrets-manager", "Secrets Manager"),
        ("acm", "Certificate Manager"),
        ("waf", "Web Application Firewall"),
        ("shield", "Shield"),
        ("guardduty", "GuardDuty"),
        ("inspector", "Inspector"),
        
        # Management
        ("cloudwatch", "CloudWatch"),
        ("cloudtrail", "CloudTrail"),
        ("config", "Config"),
        ("systems-manager", "Systems Manager"),
        ("ssm", "Systems Manager"),
        ("cloudformation", "CloudFormation"),
        ("organizations", "Organizations"),
        ("control-tower", "Control Tower"),
        
        # Analytics
        ("athena", "Athena"),
        ("emr", "Elastic MapReduce"),
        ("kinesis", "Kinesis"),
        ("glue", "Glue"),
        ("quicksight", "QuickSight"),
        
        # AI/ML
        ("sagemaker", "SageMaker"),
        ("bedrock", "Bedrock"),
        ("comprehend", "Comprehend"),
        ("rekognition", "Rekognition"),
        ("textract", "Textract"),
        ("polly", "Polly"),
        ("transcribe", "Transcribe"),
        ("translate", "Translate"),
        
        # Messaging
        ("sqs", "Simple Queue Service"),
        ("sns", "Simple Notification Service"),
        ("ses", "Simple Email Service"),
        ("eventbridge", "EventBridge"),
        ("step-functions", "Step Functions"),
    ]
    
    for service, full_name in aws_services:
        patterns[service] = to_token("AWS", service)
        patterns[f"aws {service}"] = to_token("AWS", service)
        patterns[full_name.lower()] = to_token("AWS", service)
    
    # Common AWS CLI commands
    aws_commands = {
        # General
        "aws": "@AWS:CLI",
        "aws configure": "@AWS:CONFIGURE",
        "aws sts get-caller-identity": "@AWS:WHOAMI",
        "aws sts assume-role": "@AWS:ASSUME_ROLE",
        
        # S3
        "aws s3 ls": "@AWS:S3:LS",
        "aws s3 cp": "@AWS:S3:CP",
        "aws s3 mv": "@AWS:S3:MV",
        "aws s3 rm": "@AWS:S3:RM",
        "aws s3 sync": "@AWS:S3:SYNC",
        "aws s3 mb": "@AWS:S3:MB",
        "aws s3 rb": "@AWS:S3:RB",
        "aws s3api": "@AWS:S3API",
        
        # EC2
        "aws ec2 describe-instances": "@AWS:EC2:DESC_INST",
        "aws ec2 start-instances": "@AWS:EC2:START",
        "aws ec2 stop-instances": "@AWS:EC2:STOP",
        "aws ec2 terminate-instances": "@AWS:EC2:TERMINATE",
        "aws ec2 run-instances": "@AWS:EC2:RUN",
        "aws ec2 create-image": "@AWS:EC2:CREATE_AMI",
        "aws ec2 describe-security-groups": "@AWS:EC2:DESC_SG",
        "aws ec2 authorize-security-group-ingress": "@AWS:EC2:AUTH_SG",
        
        # Lambda
        "aws lambda list-functions": "@AWS:LAMBDA:LIST",
        "aws lambda invoke": "@AWS:LAMBDA:INVOKE",
        "aws lambda create-function": "@AWS:LAMBDA:CREATE",
        "aws lambda update-function-code": "@AWS:LAMBDA:UPDATE",
        "aws lambda delete-function": "@AWS:LAMBDA:DELETE",
        
        # IAM
        "aws iam list-users": "@AWS:IAM:LIST_USERS",
        "aws iam list-roles": "@AWS:IAM:LIST_ROLES",
        "aws iam create-user": "@AWS:IAM:CREATE_USER",
        "aws iam create-role": "@AWS:IAM:CREATE_ROLE",
        "aws iam attach-role-policy": "@AWS:IAM:ATTACH_POLICY",
        "aws iam create-policy": "@AWS:IAM:CREATE_POLICY",
        
        # ECS
        "aws ecs list-clusters": "@AWS:ECS:LIST_CLUSTERS",
        "aws ecs list-services": "@AWS:ECS:LIST_SVC",
        "aws ecs describe-services": "@AWS:ECS:DESC_SVC",
        "aws ecs update-service": "@AWS:ECS:UPDATE_SVC",
        "aws ecs run-task": "@AWS:ECS:RUN_TASK",
        
        # EKS
        "aws eks list-clusters": "@AWS:EKS:LIST",
        "aws eks describe-cluster": "@AWS:EKS:DESC",
        "aws eks update-kubeconfig": "@AWS:EKS:KUBECONFIG",
        
        # CloudFormation
        "aws cloudformation create-stack": "@AWS:CFN:CREATE",
        "aws cloudformation update-stack": "@AWS:CFN:UPDATE",
        "aws cloudformation delete-stack": "@AWS:CFN:DELETE",
        "aws cloudformation describe-stacks": "@AWS:CFN:DESC",
        "aws cloudformation list-stacks": "@AWS:CFN:LIST",
        
        # CloudWatch
        "aws cloudwatch get-metric-statistics": "@AWS:CW:METRICS",
        "aws logs get-log-events": "@AWS:LOGS:GET",
        "aws logs filter-log-events": "@AWS:LOGS:FILTER",
        "aws logs describe-log-groups": "@AWS:LOGS:DESC",
    }
    patterns.update(aws_commands)
    
    # AWS phrases
    phrases = {
        "amazon web services": "@CLOUD:AWS",
        "aws cloud": "@CLOUD:AWS",
        "aws account": "@AWS:ACCOUNT",
        "aws region": "@AWS:REGION",
        "aws cli": "@AWS:CLI",
        "aws sdk": "@AWS:SDK",
        "aws console": "@AWS:CONSOLE",
        "iam role": "@AWS:IAM_ROLE",
        "iam policy": "@AWS:IAM_POLICY",
        "iam user": "@AWS:IAM_USER",
        "security group": "@AWS:SG",
        "vpc subnet": "@AWS:SUBNET",
        "internet gateway": "@AWS:IGW",
        "nat gateway": "@AWS:NAT",
        "s3 bucket": "@AWS:S3_BUCKET",
        "ec2 instance": "@AWS:EC2_INST",
        "lambda function": "@AWS:LAMBDA_FUNC",
        "rds instance": "@AWS:RDS_INST",
        "cloudformation stack": "@AWS:CFN_STACK",
        "cloudformation template": "@AWS:CFN_TPL",
        "sam template": "@AWS:SAM_TPL",
        "cdk stack": "@AWS:CDK_STACK",
    }
    patterns.update(phrases)
    
    return patterns


def build_azure_dictionary() -> dict[str, str]:
    """Build Azure CLI dictionary from common commands and services."""
    patterns = {}
    
    # Azure Services
    azure_services = [
        # Compute
        ("vm", "Virtual Machines"),
        ("vmss", "Virtual Machine Scale Sets"),
        ("aks", "Azure Kubernetes Service"),
        ("acr", "Azure Container Registry"),
        ("aci", "Azure Container Instances"),
        ("functionapp", "Azure Functions"),
        ("webapp", "Web Apps"),
        ("batch", "Azure Batch"),
        
        # Storage
        ("storage", "Azure Storage"),
        ("storage account", "Storage Account"),
        ("blob", "Blob Storage"),
        ("file", "Azure Files"),
        ("queue", "Queue Storage"),
        ("table", "Table Storage"),
        ("datalake", "Data Lake Storage"),
        
        # Database
        ("sql", "Azure SQL"),
        ("cosmosdb", "Cosmos DB"),
        ("mysql", "Azure MySQL"),
        ("postgres", "Azure PostgreSQL"),
        ("redis", "Azure Cache for Redis"),
        ("synapse", "Azure Synapse"),
        
        # Networking
        ("vnet", "Virtual Network"),
        ("nsg", "Network Security Group"),
        ("lb", "Load Balancer"),
        ("appgw", "Application Gateway"),
        ("frontdoor", "Azure Front Door"),
        ("cdn", "Azure CDN"),
        ("dns", "Azure DNS"),
        ("privatelink", "Private Link"),
        ("bastion", "Azure Bastion"),
        ("firewall", "Azure Firewall"),
        ("vpn", "VPN Gateway"),
        ("expressroute", "ExpressRoute"),
        
        # Security
        ("keyvault", "Key Vault"),
        ("ad", "Azure Active Directory"),
        ("entra", "Microsoft Entra ID"),
        ("defender", "Microsoft Defender"),
        ("sentinel", "Microsoft Sentinel"),
        
        # Management
        ("monitor", "Azure Monitor"),
        ("log-analytics", "Log Analytics"),
        ("policy", "Azure Policy"),
        ("blueprint", "Azure Blueprints"),
        ("resource-graph", "Resource Graph"),
        
        # AI/ML
        ("cognitiveservices", "Cognitive Services"),
        ("openai", "Azure OpenAI"),
        ("ml", "Azure Machine Learning"),
        
        # Integration
        ("servicebus", "Service Bus"),
        ("eventhub", "Event Hubs"),
        ("eventgrid", "Event Grid"),
        ("logic", "Logic Apps"),
        ("apim", "API Management"),
    ]
    
    for service, full_name in azure_services:
        patterns[service] = to_token("AZ", service)
        patterns[f"az {service}"] = to_token("AZ", service)
        patterns[full_name.lower()] = to_token("AZ", service)
    
    # Common Azure CLI commands
    az_commands = {
        # General
        "az": "@AZ:CLI",
        "az login": "@AZ:LOGIN",
        "az logout": "@AZ:LOGOUT",
        "az account show": "@AZ:ACCOUNT_SHOW",
        "az account set": "@AZ:ACCOUNT_SET",
        "az account list": "@AZ:ACCOUNT_LIST",
        "az configure": "@AZ:CONFIGURE",
        "az group": "@AZ:RG",
        "az group create": "@AZ:RG_CREATE",
        "az group delete": "@AZ:RG_DELETE",
        "az group list": "@AZ:RG_LIST",
        
        # VM
        "az vm create": "@AZ:VM_CREATE",
        "az vm start": "@AZ:VM_START",
        "az vm stop": "@AZ:VM_STOP",
        "az vm delete": "@AZ:VM_DELETE",
        "az vm list": "@AZ:VM_LIST",
        "az vm show": "@AZ:VM_SHOW",
        "az vm resize": "@AZ:VM_RESIZE",
        
        # AKS
        "az aks create": "@AZ:AKS_CREATE",
        "az aks delete": "@AZ:AKS_DELETE",
        "az aks get-credentials": "@AZ:AKS_CREDS",
        "az aks list": "@AZ:AKS_LIST",
        "az aks show": "@AZ:AKS_SHOW",
        "az aks scale": "@AZ:AKS_SCALE",
        "az aks upgrade": "@AZ:AKS_UPGRADE",
        
        # ACR
        "az acr create": "@AZ:ACR_CREATE",
        "az acr login": "@AZ:ACR_LOGIN",
        "az acr build": "@AZ:ACR_BUILD",
        "az acr list": "@AZ:ACR_LIST",
        
        # Storage
        "az storage account create": "@AZ:SA_CREATE",
        "az storage account list": "@AZ:SA_LIST",
        "az storage blob upload": "@AZ:BLOB_UPLOAD",
        "az storage blob download": "@AZ:BLOB_DOWNLOAD",
        "az storage blob list": "@AZ:BLOB_LIST",
        "az storage container create": "@AZ:CTR_CREATE",
        
        # Key Vault
        "az keyvault create": "@AZ:KV_CREATE",
        "az keyvault secret set": "@AZ:KV_SET",
        "az keyvault secret show": "@AZ:KV_SHOW",
        "az keyvault secret list": "@AZ:KV_LIST",
        
        # Functions
        "az functionapp create": "@AZ:FUNC_CREATE",
        "az functionapp delete": "@AZ:FUNC_DELETE",
        "az functionapp list": "@AZ:FUNC_LIST",
        
        # WebApp
        "az webapp create": "@AZ:WEB_CREATE",
        "az webapp deploy": "@AZ:WEB_DEPLOY",
        "az webapp restart": "@AZ:WEB_RESTART",
        "az webapp list": "@AZ:WEB_LIST",
        
        # Network
        "az network vnet create": "@AZ:VNET_CREATE",
        "az network nsg create": "@AZ:NSG_CREATE",
        "az network nsg rule create": "@AZ:NSG_RULE",
    }
    patterns.update(az_commands)
    
    # Azure phrases
    phrases = {
        "microsoft azure": "@CLOUD:AZURE",
        "azure cloud": "@CLOUD:AZURE",
        "azure portal": "@AZ:PORTAL",
        "azure cli": "@AZ:CLI",
        "azure powershell": "@AZ:PWSH",
        "azure sdk": "@AZ:SDK",
        "resource group": "@AZ:RG",
        "azure subscription": "@AZ:SUB",
        "azure tenant": "@AZ:TENANT",
        "managed identity": "@AZ:MI",
        "service principal": "@AZ:SP",
        "arm template": "@AZ:ARM",
        "bicep template": "@AZ:BICEP",
        "azure devops": "@AZ:DEVOPS",
        "azure pipelines": "@AZ:PIPELINE",
    }
    patterns.update(phrases)
    
    return patterns


def build_gcp_dictionary() -> dict[str, str]:
    """Build GCP CLI dictionary from common commands and services."""
    patterns = {}
    
    # GCP Services
    gcp_services = [
        # Compute
        ("compute", "Compute Engine"),
        ("gke", "Google Kubernetes Engine"),
        ("run", "Cloud Run"),
        ("functions", "Cloud Functions"),
        ("app-engine", "App Engine"),
        ("anthos", "Anthos"),
        
        # Storage
        ("storage", "Cloud Storage"),
        ("gcs", "Google Cloud Storage"),
        ("filestore", "Filestore"),
        ("persistent-disk", "Persistent Disk"),
        
        # Database
        ("sql", "Cloud SQL"),
        ("spanner", "Cloud Spanner"),
        ("bigtable", "Cloud Bigtable"),
        ("firestore", "Firestore"),
        ("datastore", "Datastore"),
        ("memorystore", "Memorystore"),
        ("alloydb", "AlloyDB"),
        
        # Networking
        ("vpc", "Virtual Private Cloud"),
        ("load-balancing", "Cloud Load Balancing"),
        ("cdn", "Cloud CDN"),
        ("dns", "Cloud DNS"),
        ("armor", "Cloud Armor"),
        ("nat", "Cloud NAT"),
        ("interconnect", "Cloud Interconnect"),
        
        # Security
        ("iam", "Cloud IAM"),
        ("kms", "Cloud KMS"),
        ("secret-manager", "Secret Manager"),
        ("security-command-center", "Security Command Center"),
        
        # Management
        ("logging", "Cloud Logging"),
        ("monitoring", "Cloud Monitoring"),
        ("trace", "Cloud Trace"),
        ("profiler", "Cloud Profiler"),
        ("deployment-manager", "Deployment Manager"),
        
        # AI/ML
        ("ai-platform", "AI Platform"),
        ("vertex-ai", "Vertex AI"),
        ("vision", "Cloud Vision"),
        ("speech", "Cloud Speech"),
        ("translate", "Cloud Translation"),
        ("natural-language", "Natural Language API"),
        
        # Data & Analytics
        ("bigquery", "BigQuery"),
        ("dataflow", "Dataflow"),
        ("dataproc", "Dataproc"),
        ("pubsub", "Pub/Sub"),
        ("composer", "Cloud Composer"),
        ("data-fusion", "Cloud Data Fusion"),
        
        # Developer Tools
        ("build", "Cloud Build"),
        ("artifact-registry", "Artifact Registry"),
        ("source-repos", "Cloud Source Repositories"),
    ]
    
    for service, full_name in gcp_services:
        patterns[service] = to_token("GCP", service)
        patterns[f"gcloud {service}"] = to_token("GCP", service)
        patterns[full_name.lower()] = to_token("GCP", service)
    
    # Common gcloud commands
    gcloud_commands = {
        # General
        "gcloud": "@GCP:CLI",
        "gcloud init": "@GCP:INIT",
        "gcloud auth login": "@GCP:AUTH_LOGIN",
        "gcloud auth application-default login": "@GCP:ADC_LOGIN",
        "gcloud config set project": "@GCP:SET_PROJECT",
        "gcloud config list": "@GCP:CONFIG_LIST",
        "gcloud projects list": "@GCP:PROJ_LIST",
        "gcloud projects create": "@GCP:PROJ_CREATE",
        
        # Compute
        "gcloud compute instances list": "@GCP:VM_LIST",
        "gcloud compute instances create": "@GCP:VM_CREATE",
        "gcloud compute instances start": "@GCP:VM_START",
        "gcloud compute instances stop": "@GCP:VM_STOP",
        "gcloud compute instances delete": "@GCP:VM_DELETE",
        "gcloud compute ssh": "@GCP:SSH",
        "gcloud compute scp": "@GCP:SCP",
        "gcloud compute firewall-rules create": "@GCP:FW_CREATE",
        "gcloud compute firewall-rules list": "@GCP:FW_LIST",
        
        # GKE
        "gcloud container clusters create": "@GCP:GKE_CREATE",
        "gcloud container clusters delete": "@GCP:GKE_DELETE",
        "gcloud container clusters get-credentials": "@GCP:GKE_CREDS",
        "gcloud container clusters list": "@GCP:GKE_LIST",
        "gcloud container clusters resize": "@GCP:GKE_RESIZE",
        
        # Cloud Run
        "gcloud run deploy": "@GCP:RUN_DEPLOY",
        "gcloud run services list": "@GCP:RUN_LIST",
        "gcloud run services delete": "@GCP:RUN_DELETE",
        
        # Functions
        "gcloud functions deploy": "@GCP:FUNC_DEPLOY",
        "gcloud functions list": "@GCP:FUNC_LIST",
        "gcloud functions delete": "@GCP:FUNC_DELETE",
        "gcloud functions call": "@GCP:FUNC_CALL",
        "gcloud functions logs read": "@GCP:FUNC_LOGS",
        
        # Storage
        "gsutil": "@GCP:GSUTIL",
        "gsutil ls": "@GCP:GS_LS",
        "gsutil cp": "@GCP:GS_CP",
        "gsutil mv": "@GCP:GS_MV",
        "gsutil rm": "@GCP:GS_RM",
        "gsutil mb": "@GCP:GS_MB",
        "gsutil rb": "@GCP:GS_RB",
        "gsutil rsync": "@GCP:GS_RSYNC",
        
        # BigQuery
        "bq": "@GCP:BQ",
        "bq query": "@GCP:BQ_QUERY",
        "bq load": "@GCP:BQ_LOAD",
        "bq extract": "@GCP:BQ_EXTRACT",
        "bq mk": "@GCP:BQ_MK",
        "bq rm": "@GCP:BQ_RM",
        "bq ls": "@GCP:BQ_LS",
        "bq show": "@GCP:BQ_SHOW",
        
        # IAM
        "gcloud iam service-accounts create": "@GCP:SA_CREATE",
        "gcloud iam service-accounts list": "@GCP:SA_LIST",
        "gcloud iam roles create": "@GCP:ROLE_CREATE",
        "gcloud projects add-iam-policy-binding": "@GCP:IAM_BIND",
        
        # Pub/Sub
        "gcloud pubsub topics create": "@GCP:PS_TOPIC_CREATE",
        "gcloud pubsub topics list": "@GCP:PS_TOPIC_LIST",
        "gcloud pubsub subscriptions create": "@GCP:PS_SUB_CREATE",
        "gcloud pubsub subscriptions pull": "@GCP:PS_PULL",
        
        # Build
        "gcloud builds submit": "@GCP:BUILD_SUBMIT",
        "gcloud builds list": "@GCP:BUILD_LIST",
        
        # Secret Manager
        "gcloud secrets create": "@GCP:SECRET_CREATE",
        "gcloud secrets versions add": "@GCP:SECRET_ADD",
        "gcloud secrets versions access": "@GCP:SECRET_ACCESS",
    }
    patterns.update(gcloud_commands)
    
    # GCP phrases
    phrases = {
        "google cloud": "@CLOUD:GCP",
        "google cloud platform": "@CLOUD:GCP",
        "gcp": "@CLOUD:GCP",
        "gcloud cli": "@GCP:CLI",
        "google cloud console": "@GCP:CONSOLE",
        "google cloud sdk": "@GCP:SDK",
        "service account": "@GCP:SA",
        "iam policy": "@GCP:IAM_POLICY",
        "iam role": "@GCP:IAM_ROLE",
        "gke cluster": "@GCP:GKE_CLUSTER",
        "cloud run service": "@GCP:RUN_SVC",
        "cloud function": "@GCP:FUNC",
        "bigquery dataset": "@GCP:BQ_DATASET",
        "bigquery table": "@GCP:BQ_TABLE",
        "pubsub topic": "@GCP:PS_TOPIC",
        "pubsub subscription": "@GCP:PS_SUB",
        "cloud storage bucket": "@GCP:GCS_BUCKET",
        "terraform gcp": "@GCP:TERRAFORM",
    }
    patterns.update(phrases)
    
    return patterns



# =============================================================================
# SOURCE 4: New Streams (Email, Data, Creative, Summary, Debug, Translate, API)
# =============================================================================

def build_email_dictionary() -> dict[str, str]:
    """Build dictionary for Email Drafting."""
    patterns = {}
    
    phrases = {
        # Greetings
        "dear": "@EMAIL:AGREEMENT_HI",
        "hello": "@EMAIL:HI",
        "hi": "@EMAIL:HI",
        "to whom it may concern": "@EMAIL:FORMAL_HI",
        
        # Closings
        "sincerely": "@EMAIL:CLOSE_FORMAL",
        "best regards": "@EMAIL:CLOSE",
        "kind regards": "@EMAIL:CLOSE_KIND",
        "warm regards": "@EMAIL:CLOSE_WARM",
        "yours faithfully": "@EMAIL:CLOSE_FAITH",
        "thanks": "@EMAIL:THANKS",
        "thank you": "@EMAIL:THANK_YOU",
        
        # Common phrases
        "please find attached": "@EMAIL:ATTACHED",
        "looking forward to": "@EMAIL:FWD_TO",
        "i hope this email finds you well": "@EMAIL:HOPE_WELL",
        "thank you for your time": "@EMAIL:THANKS_TIME",
        "as per our conversation": "@EMAIL:PER_CONVO",
        "let me know if you have any questions": "@EMAIL:LET_KNOW_Q",
        "please let me know": "@EMAIL:LET_KNOW",
        "follow up": "@EMAIL:FOLLOW_UP",
        "meeting request": "@EMAIL:MEETING_REQ",
        "calendar invite": "@EMAIL:CAL_INVITE",
        "out of office": "@EMAIL:OOO",
        "urgent": "@EMAIL:URGENT",
        "as soon as possible": "@EMAIL:ASAP",
        "for your information": "@EMAIL:FYI",
        "cc": "@EMAIL:CC",
        "bcc": "@EMAIL:BCC",
        "subject line": "@EMAIL:SUBJ",
        "reply all": "@EMAIL:REPLY_ALL",
        "forward": "@EMAIL:FWD",
    }
    
    for k, v in phrases.items():
        patterns[k] = v
        
    return patterns


def build_data_analysis_dictionary() -> dict[str, str]:
    """Build dictionary for Data Analysis."""
    patterns = {}
    
    phrases = {
        # Libs
        "pandas": "@DATA:PD",
        "numpy": "@DATA:NP",
        "matplotlib": "@DATA:PLT",
        "scikit-learn": "@DATA:SKLEARN",
        "seaborn": "@DATA:SNS",
        "tensorflow": "@DATA:TF",
        "pytorch": "@DATA:PT",
        
        # Structures
        "dataframe": "@DATA:DF",
        "series": "@DATA:SERIES",
        "array": "@DATA:ARRAY",
        "tensor": "@DATA:TENSOR",
        "matrix": "@DATA:MATRIX",
        
        # Operations
        "read_csv": "@DATA:READ_CSV",
        "to_csv": "@DATA:TO_CSV",
        "groupby": "@DATA:GROUPBY",
        "pivot table": "@DATA:PIVOT",
        "merge": "@DATA:MERGE",
        "concat": "@DATA:CONCAT",
        "describe": "@DATA:DESCRIBE",
        "value_counts": "@DATA:VAL_COUNTS",
        "fillna": "@DATA:FILLNA",
        "dropna": "@DATA:DROPNA",
        "apply": "@DATA:APPLY",
        
        # Stats
        "mean": "@DATA:MEAN",
        "median": "@DATA:MEDIAN",
        "mode": "@DATA:MODE",
        "standard deviation": "@DATA:STD",
        "variance": "@DATA:VAR",
        "correlation": "@DATA:CORR",
        "regression": "@DATA:REG",
        "hypothesis testing": "@DATA:HYPO_TEST",
        "p-value": "@DATA:P_VAL",
        "distribution": "@DATA:DIST",
        "normal distribution": "@DATA:DIST_NORM",
        "outlier": "@DATA:OUTLIER",
        "feature engineering": "@DATA:FEAT_ENG",
        
        # Visual
        "plot": "@DATA:PLOT",
        "histogram": "@DATA:HIST",
        "scatter plot": "@DATA:SCATTER",
        "line plot": "@DATA:LINE",
        "bar chart": "@DATA:BAR",
        "heatmap": "@DATA:HEATMAP",
        "boxplot": "@DATA:BOXPLOT",
    }
    
    for k, v in phrases.items():
        patterns[k] = v
        
    return patterns
    
def build_creative_writing_dictionary() -> dict[str, str]:
    """Build dictionary for Creative Writing."""
    patterns = {}
    
    phrases = {
        "once upon a time": "@STORY:START",
        "protagonist": "@STORY:HERO",
        "antagonist": "@STORY:VILLAIN",
        "plot twist": "@STORY:TWIST",
        "climax": "@STORY:CLIMAX",
        "foreshadowing": "@STORY:FORESHADOW",
        "metaphor": "@LIT:METAPHOR",
        "simile": "@LIT:SIMILE",
        "allegory": "@LIT:ALLEGORY",
        "narrative arc": "@STORY:ARC",
        "character development": "@STORY:CHAR_DEV",
        "flashback": "@STORY:FLASHBACK",
        "dialogue": "@STORY:DIALOGUE",
        "monologue": "@STORY:MONOLOGUE",
        "setting": "@STORY:SETTING",
        "theme": "@STORY:THEME",
        "genre": "@STORY:GENRE",
        "fiction": "@STORY:FICTION",
        "non-fiction": "@STORY:NON_FIC",
        "chapter": "@STORY:CHAPTER",
        "prologue": "@STORY:PROLOGUE",
        "epilogue": "@STORY:EPILOGUE",
    }
    
    for k, v in phrases.items():
        patterns[k] = v
        
    return patterns

def build_summarization_dictionary() -> dict[str, str]:
    """Build dictionary for Summarization."""
    patterns = {}
    
    phrases = {
        "in summary": "@SUM:START",
        "to conclude": "@SUM:CONCLUDE",
        "in conclusion": "@SUM:CONCLUDE",
        "key takeaways": "@SUM:TAKEAWAYS",
        "main points": "@SUM:POINTS",
        "overview": "@SUM:OVERVIEW",
        "abstract": "@SUM:ABSTRACT",
        "executive summary": "@SUM:EXEC_SUM",
        "long story short": "@SUM:SHORT",
        "briefly": "@SUM:BRIEFLY",
        "bottom line": "@SUM:BOTTOM_LINE",
        "tldr": "@SUM:TLDR",
        "tl;dr": "@SUM:TLDR",
        "summary": "@SUM:TITLE",
        "highlights": "@SUM:HIGHLIGHTS",
        "recap": "@SUM:RECAP",
    }
    
    for k, v in phrases.items():
        patterns[k] = v
        
    return patterns

def build_debugging_dictionary() -> dict[str, str]:
    """Build dictionary for Debugging."""
    patterns = {}
    
    phrases = {
        "debug": "@DBG:CMD",
        "breakpoint": "@DBG:BP",
        "stack trace": "@DBG:STACK",
        "traceback": "@DBG:TRACE",
        "exception": "@DBG:EXC",
        "error": "@DBG:ERR",
        "warning": "@DBG:WARN",
        "info": "@DBG:INFO",
        "bug": "@DBG:BUG",
        "fix": "@DBG:FIX",
        "patch": "@DBG:PATCH",
        "null pointer": "@DBG:NPE",
        "undefined": "@DBG:UNDEFINED",
        "segmentation fault": "@DBG:SEGFAULT",
        "timeout": "@DBG:TIMEOUT",
        "latency": "@DBG:LATENCY",
        "profiling": "@DBG:PROFILE",
        "memory leak": "@DBG:OOM",
        "out of memory": "@DBG:OOM",
        "syntax error": "@DBG:SYNTAX",
        "runtime error": "@DBG:RUNTIME",
        "compile error": "@DBG:COMPILE",
        "step over": "@DBG:STEP_OVER",
        "step into": "@DBG:STEP_INTO",
        "step out": "@DBG:STEP_OUT",
        "watch window": "@DBG:WATCH",
        "call stack": "@DBG:CALL_STACK",
        "console log": "@DBG:LOG",
        "print debug": "@DBG:PRINT",
    }
    
    for k, v in phrases.items():
        patterns[k] = v
        
    return patterns

def build_translation_dictionary() -> dict[str, str]:
    """Build dictionary for Translation."""
    patterns = {}
    
    phrases = {
        "translate": "@TRANS:CMD",
        "translation": "@TRANS:NOUN",
        "source language": "@TRANS:SRC",
        "target language": "@TRANS:TGT",
        "english": "@LANG:EN",
        "spanish": "@LANG:ES",
        "french": "@LANG:FR",
        "german": "@LANG:DE",
        "chinese": "@LANG:ZH",
        "japanese": "@LANG:JA",
        "korean": "@LANG:KO",
        "russian": "@LANG:RU",
        "italian": "@LANG:IT",
        "portuguese": "@LANG:PT",
        "arabic": "@LANG:AR",
        "hindi": "@LANG:HI",
        "original text": "@TRANS:ORIGINAL",
        "translated text": "@TRANS:RESULT",
        "localization": "@TRANS:L10N",
        "internationalization": "@TRANS:I18N",
    }
    
    for k, v in phrases.items():
        patterns[k] = v
        
    return patterns

def build_api_dictionary() -> dict[str, str]:
    """Build dictionary for API Interaction."""
    patterns = {}
    
    phrases = {
        # Verbs
        "get": "@API:GET",
        "post": "@API:POST",
        "put": "@API:PUT",
        "delete": "@API:DELETE",
        "patch": "@API:PATCH",
        "head": "@API:HEAD",
        "options": "@API:OPTIONS",
        
        # Concepts
        "api": "@API:TERM",
        "rest": "@API:REST",
        "graphql": "@API:GQL",
        "soap": "@API:SOAP",
        "grpc": "@API:GRPC",
        "websocket": "@API:WS",
        "endpoint": "@API:ENDPOINT",
        "url": "@API:URL",
        "uri": "@API:URI",
        "parameter": "@API:PARAM",
        "query string": "@API:QUERY",
        "path variable": "@API:PATH_VAR",
        
        # HTTP
        "http": "@API:HTTP",
        "https": "@API:HTTPS",
        "request": "@API:REQ",
        "response": "@API:RES",
        "header": "@API:HEADER",
        "body": "@API:BODY",
        "payload": "@API:PAYLOAD",
        "status code": "@API:STATUS",
        
        # Statuses
        "200 ok": "@API:200",
        "201 created": "@API:201",
        "204 no content": "@API:204",
        "301 moved": "@API:301",
        "304 not modified": "@API:304",
        "400 bad request": "@API:400",
        "401 unauthorized": "@API:401",
        "403 forbidden": "@API:403",
        "404 not found": "@API:404",
        "429 too many requests": "@API:429",
        "500 internal error": "@API:500",
        "502 bad gateway": "@API:502",
        "503 unavailable": "@API:503",
        
        # Auth
        "authentication": "@API:AUTHN",
        "authorization": "@API:AUTHZ",
        "token": "@API:TOKEN",
        "api key": "@API:KEY",
        "bearer token": "@API:BEARER",
        "oauth": "@API:OAUTH",
        "jwt": "@API:JWT",
        
        # Data
        "json": "@FMT:JSON",
        "xml": "@FMT:XML",
        "yaml": "@FMT:YAML",
        "schema": "@API:SCHEMA",
        "swagger": "@API:SWAGGER",
        "openapi": "@API:OPENAPI",
    }
    
    for k, v in phrases.items():
        patterns[k] = v
        
    return patterns


# =============================================================================
# SOURCE 5: Roleplay and Prompt Engineering Patterns
# =============================================================================

def build_prompts_dictionary() -> dict[str, str]:
    """Build dictionary for Prompt Engineering and Roleplay (from awesome-chatgpt-prompts)."""
    patterns = {}
    
    # 1. Hardcoded Universal Patterns (Top daily Usage)
    universal_patterns = {
        # Modes
        "let's think step by step": "@PROMPT:MODE:COT",
        "chain of thought": "@PROMPT:MODE:COT",
        "explain like i'm 5": "@PROMPT:MODE:ELI5",
        "explain like i am 5": "@PROMPT:MODE:ELI5",
        "eli5": "@PROMPT:MODE:ELI5",
        "pros and cons": "@PROMPT:MODE:PROS_CONS",
        "devil's advocate": "@PROMPT:MODE:DEVIL",
        "brainstorm": "@PROMPT:MODE:BRAINSTORM",
        
        # System/Control
        "ignore all previous instructions": "@PROMPT:SYS:RESET",
        "stay in character": "@PROMPT:SYS:STAY_CHAR",
        "continue generating": "@PROMPT:CMD:CONTINUE",
        "stop generating": "@PROMPT:CMD:STOP",
        "repeat the output": "@PROMPT:CMD:REPEAT",
        "rewrite this": "@PROMPT:CMD:REWRITE",
        "summarize this": "@PROMPT:CMD:SUMMARIZE",
        "tl;dr": "@PROMPT:CMD:TLDR",
        
        # Formatting
        "output as json": "@PROMPT:FMT:JSON",
        "return json": "@PROMPT:FMT:JSON",
        "output as csv": "@PROMPT:FMT:CSV",
        "return csv": "@PROMPT:FMT:CSV",
        "format as table": "@PROMPT:FMT:TABLE",
        "return markdown": "@PROMPT:FMT:MD",
        "code block only": "@PROMPT:FMT:CODE",
    }
    patterns.update(universal_patterns)
    
    # 2. Fetch "Awesome ChatGPT Prompts" CSV
    url = "https://raw.githubusercontent.com/f/awesome-chatgpt-prompts/main/prompts.csv"
    print(f"  Fetching prompts from {url}...")
    
    content = fetch_url(url)
    if content:
        try:
            # Parse CSV content
            f = io.StringIO(content)
            reader = csv.DictReader(f)
            
            for row in reader:
                act = row.get('act', '').strip()
                if not act:
                    continue
                    
                # Create token from Act name
                # e.g. "Linux Terminal" -> "LINUX_TERMINAL"
                token_suffix = act.upper().replace(" ", "_").replace("-", "_").replace("'", "")
                token_suffix = re.sub(r'[^A-Z0-9_]', '', token_suffix)
                token = f"@PROMPT:ACT:{token_suffix}"
                
                # Add various trigger phrases
                patterns[act.lower()] = token
                patterns[f"act as {act.lower()}"] = token
                patterns[f"act as a {act.lower()}"] = token
                patterns[f"act as an {act.lower()}"] = token
                
        except Exception as e:
            print(f"  [ERROR] Failed to parse prompts CSV: {e}")
            
    return patterns


# =============================================================================
# Main Entry Point
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="Carbon Protocol Dictionary Builder",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python build_dictionary.py --all
  python build_dictionary.py --python --sql
  python build_dictionary.py --kubernetes
  python build_dictionary.py --aws --azure --gcp
  python build_dictionary.py --vscode-url https://example.com/snippets.json --prefix CUSTOM
        """
    )
    
    parser.add_argument("--all", action="store_true", help="Build all dictionaries")
    parser.add_argument("--python", action="store_true", help="Build Python keywords dictionary")
    parser.add_argument("--sql", action="store_true", help="Build SQL keywords dictionary")
    parser.add_argument("--kubernetes", action="store_true", help="Build Kubernetes dictionary")
    parser.add_argument("--aws", action="store_true", help="Build AWS dictionary")
    parser.add_argument("--azure", action="store_true", help="Build Azure dictionary")
    parser.add_argument("--gcp", action="store_true", help="Build GCP dictionary")
    parser.add_argument("--email", action="store_true", help="Build Email Drafting dictionary")
    parser.add_argument("--data", action="store_true", help="Build Data Analysis dictionary")
    parser.add_argument("--creative", action="store_true", help="Build Creative Writing dictionary")
    parser.add_argument("--summary", action="store_true", help="Build Summarization dictionary")
    parser.add_argument("--debug", action="store_true", help="Build Debugging dictionary")
    parser.add_argument("--translate", action="store_true", help="Build Translation dictionary")
    parser.add_argument("--api", action="store_true", help="Build API Interaction dictionary")
    parser.add_argument("--prompts", action="store_true", help="Build Prompts/Roleplay dictionary")
    parser.add_argument("--vscode-url", type=str, help="Custom VS Code snippets URL")
    parser.add_argument("--prefix", type=str, default="CUSTOM", help="Token prefix for custom URL")
    parser.add_argument("--output", type=str, help="Output filename for custom URL")
    parser.add_argument("--dry-run", action="store_true", help="Print patterns without saving")
    
    args = parser.parse_args()
    
    # If no specific flags, show help
    if not any([args.all, args.python, args.sql, args.kubernetes, 
                args.aws, args.azure, args.gcp, args.vscode_url,
                args.email, args.data, args.creative, args.summary,
                args.debug, args.translate, args.api, args.prompts]):
        parser.print_help()
        sys.exit(0)
    
    print("=" * 60)
    print("Carbon Protocol Dictionary Builder")
    print("=" * 60)
    print(f"Output directory: {OUTPUT_DIR}")
    print()
    
    total_patterns = 0
    
    # Python
    if args.all or args.python:
        print("[1] Building Python dictionary...")
        patterns = build_python_keywords()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "lang_python.yaml", patterns, "Python keyword library", "Python")
        print()
    
    # SQL
    if args.all or args.sql:
        print("[2] Building SQL dictionary...")
        patterns = build_sql_keywords()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "lang_sql.yaml", patterns, "SQL standard keywords", "SQL")
        print()
    
    # Kubernetes
    if args.all or args.kubernetes:
        print("[3] Building Kubernetes dictionary...")
        patterns = build_kubernetes_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "tools_kubernetes.yaml", patterns, 
                     "VS Code Kubernetes snippets + kubectl commands", "Kubernetes")
        print()
    
    # AWS
    if args.all or args.aws:
        print("[4] Building AWS dictionary...")
        patterns = build_aws_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "cloud_aws.yaml", patterns, 
                     "AWS CLI commands and services", "AWS")
        print()
    
    # Azure
    if args.all or args.azure:
        print("[5] Building Azure dictionary...")
        patterns = build_azure_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "cloud_azure.yaml", patterns, 
                     "Azure CLI commands and services", "Azure")
        print()
    
    # GCP
    if args.all or args.gcp:
        print("[6] Building GCP dictionary...")
        patterns = build_gcp_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "cloud_gcp.yaml", patterns, 
                     "Google Cloud SDK commands", "GCP")
        print()
    
    # Email Drafting
    if args.all or args.email:
        print("[7] Building Email Drafting dictionary...")
        patterns = build_email_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "task_email.yaml", patterns, "Email phrases and jargon", "Email")
        print()
        
    # Data Analysis
    if args.all or args.data:
        print("[8] Building Data Analysis dictionary...")
        patterns = build_data_analysis_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "task_data_analysis.yaml", patterns, "Data Analysis terms", "Data")
        print()
        
    # Creative Writing
    if args.all or args.creative:
        print("[9] Building Creative Writing dictionary...")
        patterns = build_creative_writing_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "task_creative.yaml", patterns, "Creative Writing terms", "Creative")
        print()
        
    # Summarization
    if args.all or args.summary:
        print("[10] Building Summarization dictionary...")
        patterns = build_summarization_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "task_summary.yaml", patterns, "Summarization phrases", "Summary")
        print()
        
    # Debugging
    if args.all or args.debug:
        print("[11] Building Debugging dictionary...")
        patterns = build_debugging_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "task_debug.yaml", patterns, "Debugging terms", "Debug")
        print()
        
    # Translation
    if args.all or args.translate:
        print("[12] Building Translation dictionary...")
        patterns = build_translation_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "task_translation.yaml", patterns, "Translation terms", "Translate")
        print()
        
    # API Interaction
    if args.all or args.api:
        print("[13] Building API dictionary...")
        patterns = build_api_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "tech_api.yaml", patterns, "API Interaction terms", "API")
        print()
        
    # Roleplay Prompts
    if args.all or args.prompts:
        print("[14] Building Prompts/Roleplay dictionary...")
        patterns = build_prompts_dictionary()
        total_patterns += len(patterns)
        if args.dry_run:
            for k, v in sorted(patterns.items())[:20]:
                print(f"    {k}: {v}")
            print(f"    ... and {len(patterns) - 20} more")
        else:
            save_yaml(OUTPUT_DIR / "prompts_common.yaml", patterns, "Awesome ChatGPT Prompts + Top Patterns", "Prompts")
        print()

    
    # Custom VS Code URL
    if args.vscode_url:
        print(f"[Custom] Building from URL: {args.vscode_url}")
        patterns = build_vscode_snippets(args.vscode_url, args.prefix, "Custom")
        total_patterns += len(patterns)
        if patterns:
            if args.dry_run:
                for k, v in sorted(patterns.items())[:20]:
                    print(f"    {k}: {v}")
            else:
                output_name = args.output or f"custom_{args.prefix.lower()}.yaml"
                save_yaml(OUTPUT_DIR / output_name, patterns, args.vscode_url, args.prefix)
        print()
    
    print("=" * 60)
    print(f"Total patterns generated: {total_patterns}")
    if not args.dry_run:
        print(f"Output directory: {OUTPUT_DIR}")
    print("=" * 60)


if __name__ == "__main__":
    main()
